{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RobertVoropaev/NLP_notes/blob/main/stepic_nlp_task1_20newsgroups.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfNH8XmB3VrB"
   },
   "source": [
    "# Тематическая классификация длинных текстов - TFIDF и LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.265628Z",
     "start_time": "2019-09-12T12:42:55.188211Z"
    },
    "id": "APt42vvM3VrH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/rv/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD:task1_20newsgroups.ipynb
=======
    "# Если Вы запускаете ноутбук на colab или kaggle,\n",
    "# выполните следующие строчки, чтобы подгрузить библиотеку dlnlputils:\n",
    "\n",
    "!git clone -q https://github.com/Samsung-IT-Academy/stepik-dl-nlp.git \n",
    "!pip install -q -r stepik-dl-nlp/requirements.txt\n",
    "import sys\n",
    "sys.path.append('./stepik-dl-nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.265628Z",
     "start_time": "2019-09-12T12:42:55.188211Z"
    },
    "id": "APt42vvM3VrH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/voropaev_ri/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/voropaev_ri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "khTuGNosEW-A"
   },
   "outputs": [],
   "source": [
    "def init_random_seed(value=0):\n",
    "    random.seed(value)\n",
    "    np.random.seed(value)\n",
    "    torch.manual_seed(value)\n",
    "    torch.cuda.manual_seed(value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "init_random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCZ79ma53VrJ"
   },
   "source": [
    "## Предобработка текстов и подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkOMwSjyoZjA"
   },
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:42:57.847399Z",
     "start_time": "2019-09-12T12:42:57.268037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pye5bxRy3VrJ",
    "outputId": "6fbc777d-2654-4d80-d9a7-61f92d9bbf37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество обучающих текстов 11314\n",
      "Количество тестовых текстов 7532\n",
      "Ключи в данных: dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n",
      "\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "Метка 7\n",
      "Название метки rec.autos\n"
     ]
    }
   ],
   "source": [
    "train_source = fetch_20newsgroups(subset='train')\n",
    "test_source = fetch_20newsgroups(subset='test')\n",
    "\n",
    "print('Количество обучающих текстов', len(train_source['data']))\n",
    "print('Количество тестовых текстов', len(test_source['data']))\n",
    "print(f'Ключи в данных: {train_source.keys()}')\n",
    "print()\n",
    "print(train_source['data'][0].strip())\n",
    "\n",
    "print()\n",
    "print('Метка', train_source['target'][0])\n",
    "print('Название метки', train_source[\"target_names\"][train_source['target'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gJ_GLtj3VrK"
   },
   "source": [
    "### Подготовка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL8VwZs6ofvP"
   },
   "source": [
    "#### Токенизакция - разбиение на отдельные слова"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:task1_20newsgroups.ipynb
   "execution_count": 4,
=======
   "execution_count": 10,
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "def tokenize_text_simple_regex(txt: str, \n",
    "                               token_pattern: re.Pattern = TOKEN_RE, \n",
    "                               min_token_size: int = 4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = token_pattern.findall(txt)\n",
    "    return list(filter(lambda x: len(x) >= min_token_size, all_tokens))\n",
    "\n",
    "\n",
    "def character_tokenize(txt):\n",
    "    return list(txt)\n",
    "\n",
    "\n",
    "def tokenize_corpus(texts, \n",
    "                    tokenizer=tokenize_text_simple_regex, \n",
    "                    **tokenizer_kwargs):\n",
    "    return [tokenizer(text, **tokenizer_kwargs) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:task1_20newsgroups.ipynb
   "execution_count": 5,
=======
   "execution_count": 11,
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QQtdn9lozIg",
    "outputId": "ee88c25f-815c-46f1-fd87-66c072c57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'lerxst', 'where', 'thing', 'subject', 'what', 'this', 'nntp', 'posting', 'host', 'rac3', 'organization', 'university', 'maryland', 'college', 'park', 'lines', 'wondering', 'anyone', 'there', 'could', 'enlighten', 'this', 'other', 'door', 'sports', 'looked', 'from', 'late', 'early', 'called', 'bricklin', 'doors', 'were', 'really', 'small', 'addition', 'front', 'bumper', 'separate', 'from', 'rest', 'body', 'this', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'production', 'where', 'this', 'made', 'history', 'whatever', 'info', 'have', 'this', 'funky', 'looking', 'please', 'mail', 'thanks', 'brought', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "train_tokenized = tokenize_corpus(train_source['data'])\n",
    "test_tokenized = tokenize_corpus(test_source['data'])\n",
    "\n",
    "print(train_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4cQ83qZsGe_"
   },
   "source": [
    "### Построение словаря - отображение слов в номера"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:task1_20newsgroups.ipynb
   "execution_count": 6,
=======
   "execution_count": 12,
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
   "metadata": {
    "id": "zglNvOAdskE3"
   },
   "outputs": [],
   "source": [
    "def add_fake_token(word2id, token='<PAD>'):\n",
    "    word2id_new = {token: i + 1 for token, i in word2id.items()}\n",
    "    word2id_new[token] = 0\n",
    "    return word2id_new\n",
    "\n",
    "\n",
    "def texts_to_token_ids(tokenized_texts, word2id):\n",
    "    return [[word2id[token] for token in text if token in word2id]\n",
    "            for text in tokenized_texts]\n",
    "\n",
    "\n",
    "def build_vocabulary(tokenized_texts, \n",
    "                     max_size=1000000, \n",
    "                     max_doc_freq=0.8, \n",
    "                     min_count=5, \n",
    "                     pad_word=None):\n",
    "    word_counts = collections.defaultdict(int)\n",
    "    doc_n = 0\n",
    "\n",
    "    # посчитать количество документов, в которых употребляется каждое слово\n",
    "    # а также общее количество документов\n",
    "    for txt in tokenized_texts:\n",
    "        doc_n += 1\n",
    "        for token in set(txt):\n",
    "            word_counts[token] += 1\n",
    "\n",
    "    # убрать слишком редкие и слишком частые слова\n",
    "    word_counts = {word: cnt for word, cnt in word_counts.items()\n",
    "                   if cnt >= min_count and cnt / doc_n <= max_doc_freq}\n",
    "\n",
    "    # отсортировать слова по убыванию частоты\n",
    "    # для того, чтобы самые частые получили наименьший идентификатор\n",
    "    sorted_word_counts = sorted(word_counts.items(),\n",
    "                                reverse=True,\n",
    "                                key=lambda pair: pair[1])\n",
    "\n",
    "    # добавим несуществующее слово с индексом 0 для удобства пакетной обработки\n",
    "    if pad_word is not None:\n",
    "        sorted_word_counts = [(pad_word, 0)] + sorted_word_counts\n",
    "\n",
    "    # если у нас по прежнему слишком много слов, оставить только max_size самых частотных\n",
    "    if len(word_counts) > max_size:\n",
    "        sorted_word_counts = sorted_word_counts[:max_size]\n",
    "\n",
    "    # нумеруем слова\n",
    "    word2id = {word: i for i, (word, _) in enumerate(sorted_word_counts)}\n",
    "\n",
    "    # нормируем частоты слов\n",
    "    word2freq = np.array([cnt / doc_n for _, cnt in sorted_word_counts], dtype='float32')\n",
    "\n",
    "    return word2id, word2freq"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:task1_20newsgroups.ipynb
   "execution_count": 7,
=======
   "execution_count": 13,
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:00.825372Z",
     "start_time": "2019-09-12T12:43:00.297392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxtcXlfu3VrL",
    "outputId": "ffd97769-0e4c-4486-9ea8-cc4fd6ece9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных токенов 21628\n",
      "[('that', 0), ('this', 1), ('have', 2), ('with', 3), ('writes', 4), ('article', 5), ('posting', 6), ('host', 7), ('nntp', 8), ('there', 9)]\n"
     ]
    }
   ],
   "source": [
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5\n",
    "vocabulary, word_doc_freq = build_vocabulary(train_tokenized, \n",
    "                                             max_doc_freq=MAX_DF, \n",
    "                                             min_count=MIN_COUNT)\n",
    "UNIQUE_WORDS_N = len(vocabulary)\n",
    "print('Количество уникальных токенов', UNIQUE_WORDS_N)\n",
    "print(list(vocabulary.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:43:01.524600Z",
     "start_time": "2019-09-12T12:43:00.829107Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "-Of10KXV3VrM",
    "outputId": "361f85e4-cab8-4303-e34e-710c8939df64"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(word_doc_freq, bins=20)\n",
    "plt.title('Распределение относительных частот слов')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8_1697kAb0E"
   },
   "source": [
    "### Построение матрицы признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = scipy.sparse.dok_matrix((len(train_tokenized), len(vocabulary)), \n",
    "                                 dtype='float32')\n",
    "\n",
    "for text_i, text in enumerate(train_tokenized):\n",
    "    for token in text:\n",
    "        if token in vocabulary:\n",
    "            result[text_i, vocabulary[token]] += 1\n",
    "            \n",
    "result.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HATJm77PAnBP"
   },
   "outputs": [],
   "source": [
    "def vectorize_texts(tokenized_texts, \n",
    "                    word2id, \n",
    "                    word2freq, \n",
    "                    mode='tfidf', \n",
    "                    scale=True):\n",
    "    \n",
    "    assert mode in {'tfidf', 'idf', 'tf', 'bin'}\n",
    "\n",
    "    # строим разряженную матрицу документ-слово\n",
    "    result = scipy.sparse.dok_matrix((len(tokenized_texts), len(word2id)), \n",
    "                                     dtype='float32')\n",
    "    \n",
    "    # считаем количество употреблений каждого слова в каждом документе\n",
    "    for text_i, text in enumerate(tokenized_texts):\n",
    "        for token in text:\n",
    "            if token in word2id:\n",
    "                result[text_i, word2id[token]] += 1\n",
    "\n",
    "    # получаем бинарные вектора \"встречается или нет\"\n",
    "    if mode == 'bin':\n",
    "        result = (result > 0).astype('float32')\n",
    "\n",
    "    # получаем вектора относительных частот слова в документе\n",
    "    elif mode == 'tf':\n",
    "        result = result.tocsr() # обеспечивает быстрые операции со строками разряженной матрицы\n",
    "        result = result.multiply(1 / result.sum(axis=1)) # делим каждый токен в документе на длину этого документа (сумма по строке)\n",
    "\n",
    "    # полностью убираем информацию о количестве употреблений слова в данном документе,\n",
    "    # но оставляем информацию о частотности слова в корпусе в целом\n",
    "    elif mode == 'idf':\n",
    "        result = (result > 0).astype('float32').multiply(1 / word2freq)\n",
    "\n",
    "    # учитываем всю информацию, которая у нас есть:\n",
    "    # частоту слова в документе и частоту слова в корпусе\n",
    "    elif mode == 'tfidf':\n",
    "        result = result.tocsr() \n",
    "        result = result.multiply(1 / result.sum(axis=1))  # разделить каждую строку на её длину\n",
    "        result = result.multiply(1 / word2freq)  # разделить каждый столбец на вес слова\n",
    "\n",
    "    # стандартизация весов - отображение в 0-1\n",
    "    # приведение к норм. виду испортит разряженность матрицы\n",
    "    if scale: \n",
    "        result = result.tocsc()\n",
    "        result -= result.min()\n",
    "        result /= (result.max() + 1e-6) # eps для нулевого максимума\n",
    "\n",
    "    return result.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.094816Z",
     "start_time": "2019-09-12T12:43:01.526554Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTRihyTz3VrM",
    "outputId": "4d4e8ff7-27ae-455d-8e0e-73b56cbe875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность матрицы признаков обучающей выборки (11314, 21628)\n",
      "Размерность матрицы признаков тестовой выборки (7532, 21628)\n",
      "\n",
      "Количество ненулевых элементов в обучающей выборке 1126792\n",
      "Процент заполненности матрицы признаков 0.46%\n",
      "\n",
      "Количество ненулевых элементов в тестовой выборке 721529\n",
      "Процент заполненности матрицы признаков 0.44%\n"
     ]
    }
   ],
   "source": [
    "VECTORIZATION_MODE = 'tfidf'\n",
    "train_vectors = vectorize_texts(train_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "test_vectors = vectorize_texts(test_tokenized, vocabulary, word_doc_freq, mode=VECTORIZATION_MODE)\n",
    "\n",
    "print('Размерность матрицы признаков обучающей выборки', train_vectors.shape)\n",
    "print('Размерность матрицы признаков тестовой выборки', test_vectors.shape)\n",
    "print()\n",
    "print('Количество ненулевых элементов в обучающей выборке', train_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(train_vectors.nnz * 100 / (train_vectors.shape[0] * train_vectors.shape[1])))\n",
    "print()\n",
    "print('Количество ненулевых элементов в тестовой выборке', test_vectors.nnz)\n",
    "print('Процент заполненности матрицы признаков {:.2f}%'.format(test_vectors.nnz * 100 / (test_vectors.shape[0] * test_vectors.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.857114Z",
     "start_time": "2019-09-12T12:44:16.098773Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "H7JGr7P-3VrN",
    "outputId": "76c96a32-19d0-4b56-c57f-4821e7e37955"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_vectors.data, bins=20)\n",
    "plt.title('Распределение весов признаков')\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uES1cM8G3VrR"
   },
   "source": [
    "### Распределение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:16.864960Z",
     "start_time": "2019-09-12T12:44:16.859476Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "GiEx_AlV3VrR",
    "outputId": "1b49cc25-dae9-405e-b80d-b5ae559a5508"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных меток 20\n"
     ]
    }
   ],
   "source": [
    "UNIQUE_LABELS_N = len(set(train_source['target']))\n",
    "print('Количество уникальных меток', UNIQUE_LABELS_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.106036Z",
     "start_time": "2019-09-12T12:44:16.867310Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "PMbS5sFr3VrR",
    "outputId": "3adb5419-8a33-4027-bfbf-ec5a0b910036"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в обучающей выборке');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.312198Z",
     "start_time": "2019-09-12T12:44:17.109884Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "6BCZsMgr3VrS",
    "outputId": "e9525bac-cff7-4285-822f-b710ca610989",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_source['target'], bins=np.arange(0, 21))\n",
    "plt.title('Распределение меток в тестовой выборке');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jlwyJhd3VrS"
   },
   "source": [
    "### PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:44:17.319292Z",
     "start_time": "2019-09-12T12:44:17.315074Z"
    },
    "id": "i9bvZ3-J3VrS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SparseFeaturesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для работы и загрузки в модель данных из разреженной матрицы\n",
    "    \n",
    "    Dataset - интерфейс для удобной загрузки данных в pytorch\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 features: scipy.sparse.csr.csr_matrix, \n",
    "                 targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np_features = self.features[idx].toarray()[0] #конвертируем в плотное представление\n",
    "        np_target = np.asarray(self.targets[idx])\n",
    "\n",
    "        cur_features = torch.from_numpy(np_features).float()\n",
    "        cur_label = torch.from_numpy(np_target).long()\n",
    "        return cur_features, cur_label\n",
    "\n",
    "\n",
    "train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000e+00, 2.5308e-04, 5.1471e-05,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]),\n",
       " tensor(7))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SadDOjYF3VrS"
   },
   "source": [
    "## Обучение модели на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tg68XfacESTH"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def copy_data_to_device(data, device):\n",
    "    if torch.is_tensor(data):\n",
    "        return data.to(device)\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        return [copy_data_to_device(elem, device) for elem in data]\n",
    "    raise ValueError('Unknown data type {}'.format(type(data)))\n",
    "\n",
    "\n",
    "def print_grad_stats(model):\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    norm = 1e-5\n",
    "    for param in model.parameters():\n",
    "        grad = getattr(param, 'grad', None)\n",
    "        if grad is not None:\n",
    "            mean += grad.data.abs().mean()\n",
    "            std += grad.data.std()\n",
    "            best_val_loss, best_model = train_eval_loop(\n",
    "                trainer,\n",
    "                train_dataset,\n",
    "                test_dataset,\n",
    "                criterion=no_loss,\n",
    "                lr=1e-2,\n",
    "                epoch_n=2,\n",
    "                batch_size=8,\n",
    "                device='cpu',\n",
    "                early_stopping_patience=10,\n",
    "                max_batches_per_epoch_train=2000,\n",
    "                max_batches_per_epoch_val=len(test_dataset),\n",
    "                lr_scheduler_ctor=lambda optim: torch.optim.lr_scheduler.ReduceLROnPlateau(optim, \n",
    "                                                                                           patience=1, \n",
    "                                                                                           verbose=True)\n",
    "            )\n",
    "            norm += 1\n",
    "    mean /= norm\n",
    "    std /= norm\n",
    "    print(f'Mean grad {mean}, std {std}, n {norm}')\n",
    "\n",
    "\n",
    "def train_eval_loop(model, \n",
    "                    train_dataset, \n",
    "                    val_dataset, \n",
    "                    criterion,\n",
    "                    lr=1e-4, \n",
    "                    epoch_n=10, \n",
    "                    batch_size=32,\n",
    "                    device=None, \n",
    "                    early_stopping_patience=10, \n",
    "                    l2_reg_alpha=0,\n",
    "                    max_batches_per_epoch_train=10000,\n",
    "                    max_batches_per_epoch_val=1000,\n",
    "                    data_loader_ctor=DataLoader,\n",
    "                    optimizer_ctor=None,\n",
    "                    lr_scheduler_ctor=None,\n",
    "                    shuffle_train=True,\n",
    "                    dataloader_workers_n=0):\n",
    "    \"\"\"\n",
    "    Цикл для обучения модели. После каждой эпохи качество модели оценивается по отложенной выборке.\n",
    "    :param model: torch.nn.Module - обучаемая модель\n",
    "    :param train_dataset: torch.utils.data.Dataset - данные для обучения\n",
    "    :param val_dataset: torch.utils.data.Dataset - данные для оценки качества\n",
    "    :param criterion: функция потерь для настройки модели\n",
    "    :param lr: скорость обучения\n",
    "    :param epoch_n: максимальное количество эпох\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param early_stopping_patience: наибольшее количество эпох, в течение которых допускается\n",
    "        отсутствие улучшения модели, чтобы обучение продолжалось.\n",
    "    :param l2_reg_alpha: коэффициент L2-регуляризации\n",
    "    :param max_batches_per_epoch_train: максимальное количество итераций на одну эпоху обучения\n",
    "    :param max_batches_per_epoch_val: максимальное количество итераций на одну эпоху валидации\n",
    "    :param data_loader_ctor: функция для создания объекта, преобразующего датасет в батчи\n",
    "        (по умолчанию torch.utils.data.DataLoader)\n",
    "    :return: кортеж из двух элементов:\n",
    "        - среднее значение функции потерь на валидации на лучшей эпохе\n",
    "        - лучшая модель\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # перенос модели на устройство вычисления\n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # создение оптимизатора\n",
    "    if optimizer_ctor is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                     lr=lr, \n",
    "                                     weight_decay=l2_reg_alpha)\n",
    "    else:\n",
    "        optimizer = optimizer_ctor(model.parameters(), \n",
    "                                   lr=lr)\n",
    "\n",
    "    # настройка изменения скорости обучения\n",
    "    if lr_scheduler_ctor is not None:\n",
    "        lr_scheduler = lr_scheduler_ctor(optimizer)\n",
    "    else:\n",
    "        lr_scheduler = None\n",
    "\n",
    "    # создаём dataloader - класс pytorch, позволяющий в многопоточном режиме собирать датасеты\n",
    "    train_dataloader = data_loader_ctor(train_dataset, \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=shuffle_train,\n",
    "                                        num_workers=dataloader_workers_n)\n",
    "    \n",
    "    val_dataloader = data_loader_ctor(val_dataset, \n",
    "                                      batch_size=batch_size, \n",
    "                                      shuffle=False,\n",
    "                                      num_workers=dataloader_workers_n)\n",
    "    \n",
    "    # инициализация сохранения лучших параметров \n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch_i = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "\n",
    "    # цикл обучения\n",
    "    for epoch_i in range(epoch_n):\n",
    "        try:\n",
    "            epoch_start = datetime.datetime.now()\n",
    "            print('Эпоха {}'.format(epoch_i))\n",
    "\n",
    "            model.train() # перевод модели в режим обучения, необх. для корр. dropout и batchnorm\n",
    "\n",
    "            mean_train_loss = 0\n",
    "            train_batches_n = 0\n",
    "            for batch_i, (batch_x, batch_y) in enumerate(train_dataloader):\n",
    "                # указанное количество шагов в эпоху\n",
    "                if batch_i > max_batches_per_epoch_train:\n",
    "                    break\n",
    "\n",
    "                # копирование данных на устройство модели\n",
    "                batch_x = copy_data_to_device(batch_x, device)\n",
    "                batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                pred = model(batch_x) # прямой проход\n",
    "                loss = criterion(pred, batch_y) # критерий ошибки\n",
    "\n",
    "                model.zero_grad() # очистка градиентов с прошлого шага\n",
    "                loss.backward() # находим новые градиенты\n",
    "                optimizer.step() # делаем градиентный шаг\n",
    "\n",
    "                mean_train_loss += float(loss)\n",
    "                train_batches_n += 1\n",
    "\n",
    "            mean_train_loss /= train_batches_n\n",
    "            print('Эпоха: {} итераций, {:0.2f} сек'.format(train_batches_n,\n",
    "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\n",
    "            print('Среднее значение функции потерь на обучении', mean_train_loss)\n",
    "\n",
    "            \n",
    "            ### Валидация\n",
    "\n",
    "            model.eval() # перевод модели в режим предсказания\n",
    "            mean_val_loss = 0\n",
    "            val_batches_n = 0\n",
    "\n",
    "            with torch.no_grad(): # выключение сохранения градиентов - экономит ресурсы\n",
    "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\n",
    "                    if batch_i > max_batches_per_epoch_val:\n",
    "                        break\n",
    "\n",
    "                    batch_x = copy_data_to_device(batch_x, device)\n",
    "                    batch_y = copy_data_to_device(batch_y, device)\n",
    "\n",
    "                    pred = model(batch_x)\n",
    "                    loss = criterion(pred, batch_y)\n",
    "\n",
    "                    mean_val_loss += float(loss)\n",
    "                    val_batches_n += 1\n",
    "\n",
    "            mean_val_loss /= val_batches_n\n",
    "            print('Среднее значение функции потерь на валидации', mean_val_loss)\n",
    "\n",
    "            # сохранение лучшей модели\n",
    "            if mean_val_loss < best_val_loss:\n",
    "                best_epoch_i = epoch_i\n",
    "                best_val_loss = mean_val_loss\n",
    "                best_model = copy.deepcopy(model)\n",
    "                print('Новая лучшая модель!')\n",
    "            elif epoch_i - best_epoch_i > early_stopping_patience:\n",
    "                print('Модель не улучшилась за последние {} эпох, прекращаем обучение'.format(\n",
    "                    early_stopping_patience))\n",
    "                break\n",
    "\n",
    "            # если задано расписание - обновить lr\n",
    "            if lr_scheduler is not None:\n",
    "                lr_scheduler.step(mean_val_loss)\n",
    "\n",
    "            print()\n",
    "        \n",
    "        # обработка исключений\n",
    "        except KeyboardInterrupt:\n",
    "            print('Досрочно остановлено пользователем')\n",
    "            break\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print('Ошибка при обучении: {}\\n{}'.format(ex, traceback.format_exc()))\n",
    "            break\n",
    "\n",
    "    return best_val_loss, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:22.371272Z",
     "start_time": "2019-09-12T12:44:17.322178Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VQ8bGIy3VrS",
    "outputId": "5a53392e-74f1-4cb6-9c4d-383455b2856b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Эпоха 0\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 2.5830741812673845\n",
      "Среднее значение функции потерь на валидации 2.508094621916949\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 1.6118252893512168\n",
      "Среднее значение функции потерь на валидации 2.132260043742293\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 89 итераций, 0.69 сек\n",
      "Среднее значение функции потерь на обучении 1.027065696341268\n",
      "Среднее значение функции потерь на валидации 1.879936396065405\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.703178877241156\n",
      "Среднее значение функции потерь на валидации 1.7122873471955122\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 89 итераций, 0.89 сек\n",
      "Среднее значение функции потерь на обучении 0.5112808139136668\n",
      "Среднее значение функции потерь на валидации 1.593126729383307\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.3915659393487352\n",
      "Среднее значение функции потерь на валидации 1.5034330739813335\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 89 итераций, 0.68 сек\n",
      "Среднее значение функции потерь на обучении 0.309796302673522\n",
      "Среднее значение функции потерь на валидации 1.4373567730693493\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.25193539094389156\n",
      "Среднее значение функции потерь на валидации 1.3882593967146792\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 89 итераций, 1.24 сек\n",
      "Среднее значение функции потерь на обучении 0.20962911074081164\n",
      "Среднее значение функции потерь на валидации 1.3405282901505293\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.17696532782878768\n",
      "Среднее значение функции потерь на валидации 1.3030094554868794\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 89 итераций, 1.23 сек\n",
      "Среднее значение функции потерь на обучении 0.1517282778794846\n",
      "Среднее значение функции потерь на валидации 1.2741706856226518\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.13150747672895366\n",
      "Среднее значение функции потерь на валидации 1.2427941217260845\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 89 итераций, 0.94 сек\n",
      "Среднее значение функции потерь на обучении 0.11515948988413544\n",
      "Среднее значение функции потерь на валидации 1.2226668111348555\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.10150293218955565\n",
      "Среднее значение функции потерь на валидации 1.201039731502533\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.09035683657681004\n",
      "Среднее значение функции потерь на валидации 1.1844113762095823\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 15\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.08077885620714573\n",
      "Среднее значение функции потерь на валидации 1.1657937653994157\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 16\n",
      "Эпоха: 89 итераций, 0.69 сек\n",
      "Среднее значение функции потерь на обучении 0.07309496059511485\n",
      "Среднее значение функции потерь на валидации 1.1495000770536519\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 17\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.06578041918659477\n",
      "Среднее значение функции потерь на валидации 1.138087810096094\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 18\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.05971924542041307\n",
      "Среднее значение функции потерь на валидации 1.1239172230332584\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 19\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.05467498268973961\n",
      "Среднее значение функции потерь на валидации 1.1191684957277976\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 20\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.04994065833560536\n",
      "Среднее значение функции потерь на валидации 1.1091999047893588\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 21\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.04574302537889963\n",
      "Среднее значение функции потерь на валидации 1.095372381856886\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 22\n",
      "Эпоха: 89 итераций, 1.21 сек\n",
      "Среднее значение функции потерь на обучении 0.0422082097175416\n",
      "Среднее значение функции потерь на валидации 1.086404445817915\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 23\n",
      "Эпоха: 89 итераций, 1.18 сек\n",
      "Среднее значение функции потерь на обучении 0.03906886873955137\n",
      "Среднее значение функции потерь на валидации 1.078098079915774\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 24\n",
      "Эпоха: 89 итераций, 1.22 сек\n",
      "Среднее значение функции потерь на обучении 0.03619799105806297\n",
      "Среднее значение функции потерь на валидации 1.0733889937400818\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 25\n",
      "Эпоха: 89 итераций, 1.18 сек\n",
      "Среднее значение функции потерь на обучении 0.033536745821324626\n",
      "Среднее значение функции потерь на валидации 1.0657290745589694\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 26\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.031117740830176332\n",
      "Среднее значение функции потерь на валидации 1.060941270852493\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 27\n",
      "Эпоха: 89 итераций, 1.23 сек\n",
      "Среднее значение функции потерь на обучении 0.02902767685859391\n",
      "Среднее значение функции потерь на валидации 1.051481823799974\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 28\n",
      "Эпоха: 89 итераций, 1.22 сек\n",
      "Среднее значение функции потерь на обучении 0.02727763955429029\n",
      "Среднее значение функции потерь на валидации 1.0488196672019312\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 29\n",
      "Эпоха: 89 итераций, 1.18 сек\n",
      "Среднее значение функции потерь на обучении 0.025524937798886486\n",
      "Среднее значение функции потерь на валидации 1.043677289607161\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 30\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.023785985231901823\n",
      "Среднее значение функции потерь на валидации 1.0375318446401822\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 31\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.022384626738559663\n",
      "Среднее значение функции потерь на валидации 1.0356954861495455\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 32\n",
      "Эпоха: 89 итераций, 1.24 сек\n",
      "Среднее значение функции потерь на обучении 0.020949046671641675\n",
      "Среднее значение функции потерь на валидации 1.026697626558401\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 33\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.019912506202549748\n",
      "Среднее значение функции потерь на валидации 1.024621778625553\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 34\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.01893140096217394\n",
      "Среднее значение функции потерь на валидации 1.019849265025834\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 35\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.01769852229090554\n",
      "Среднее значение функции потерь на валидации 1.0171278058472326\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 36\n",
      "Эпоха: 89 итераций, 0.67 сек\n",
      "Среднее значение функции потерь на обучении 0.016768546178518386\n",
      "Среднее значение функции потерь на валидации 1.0136664146083896\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 37\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.015812205820438567\n",
      "Среднее значение функции потерь на валидации 1.0081069045147653\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 38\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.014971143576536285\n",
      "Среднее значение функции потерь на валидации 1.0055278832629575\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 39\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.014237629375263546\n",
      "Среднее значение функции потерь на валидации 1.0067201135522228\n",
      "\n",
      "Эпоха 40\n",
      "Эпоха: 89 итераций, 1.16 сек\n",
      "Среднее значение функции потерь на обучении 0.013545702975452616\n",
      "Среднее значение функции потерь на валидации 1.0006731102022075\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 41\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.013002369479600633\n",
      "Среднее значение функции потерь на валидации 1.0000623444379386\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 42\n",
      "Эпоха: 89 итераций, 1.25 сек\n",
      "Среднее значение функции потерь на обучении 0.012191914288808456\n",
      "Среднее значение функции потерь на валидации 0.9927041581121542\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 43\n",
      "Эпоха: 89 итераций, 0.74 сек\n",
      "Среднее значение функции потерь на обучении 0.01159728029114979\n",
      "Среднее значение функции потерь на валидации 0.9905938526331368\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.011152971195831392\n",
      "Среднее значение функции потерь на валидации 0.9912244455289032\n",
      "\n",
      "Эпоха 45\n",
      "Эпоха: 89 итераций, 0.67 сек\n",
      "Среднее значение функции потерь на обучении 0.0106047818939505\n",
      "Среднее значение функции потерь на валидации 0.9884193408287177\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 46\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.010143639483185632\n",
      "Среднее значение функции потерь на валидации 0.9913746037725675\n",
      "\n",
      "Эпоха 47\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.009714919100567865\n",
      "Среднее значение функции потерь на валидации 0.9866703657780663\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 48\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.00926274365714092\n",
      "Среднее значение функции потерь на валидации 0.9828211877305629\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 49\n",
      "Эпоха: 89 итераций, 0.67 сек\n",
      "Среднее значение функции потерь на обучении 0.00880991340499748\n",
      "Среднее значение функции потерь на валидации 0.9819135999275466\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 50\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.0087634112026668\n",
      "Среднее значение функции потерь на валидации 0.9818485995470467\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 51\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.008241962390334418\n",
      "Среднее значение функции потерь на валидации 0.978419490789963\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 52\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.0077537816708509845\n",
      "Среднее значение функции потерь на валидации 0.9771377767546702\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 53\n",
      "Эпоха: 89 итераций, 0.88 сек\n",
      "Среднее значение функции потерь на обучении 0.0075272292374853\n",
      "Среднее значение функции потерь на валидации 0.9748146533966064\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 54\n",
      "Эпоха: 89 итераций, 1.22 сек\n",
      "Среднее значение функции потерь на обучении 0.00724723658608168\n",
      "Среднее значение функции потерь на валидации 0.9702912084126877\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 55\n",
      "Эпоха: 89 итераций, 1.22 сек\n",
      "Среднее значение функции потерь на обучении 0.0068679693458455334\n",
      "Среднее значение функции потерь на валидации 0.9744487899844929\n",
      "\n",
      "Эпоха 56\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.006543392098372739\n",
      "Среднее значение функции потерь на валидации 0.968157027737569\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 57\n",
      "Эпоха: 89 итераций, 1.22 сек\n",
      "Среднее значение функции потерь на обучении 0.00629155028590493\n",
      "Среднее значение функции потерь на валидации 0.9696832996303753\n",
      "\n",
      "Эпоха 58\n",
      "Эпоха: 89 итераций, 0.97 сек\n",
      "Среднее значение функции потерь на обучении 0.006153826405597704\n",
      "Среднее значение функции потерь на валидации 0.9683161044524888\n",
      "\n",
      "Эпоха 59\n",
      "Эпоха: 89 итераций, 0.62 сек\n",
      "Среднее значение функции потерь на обучении 0.005851681849113509\n",
      "Среднее значение функции потерь на валидации 0.9658640592785205\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 60\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.005689236202036564\n",
      "Среднее значение функции потерь на валидации 0.9688630690008907\n",
      "\n",
      "Эпоха 61\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.005488280696124675\n",
      "Среднее значение функции потерь на валидации 0.9600665145001169\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 62\n",
      "Эпоха: 89 итераций, 0.61 сек\n",
      "Среднее значение функции потерь на обучении 0.005368721239750137\n",
      "Среднее значение функции потерь на валидации 0.9636939561973183\n",
      "\n",
      "Эпоха 63\n",
      "Эпоха: 89 итераций, 0.62 сек\n",
      "Среднее значение функции потерь на обучении 0.005170862841827983\n",
      "Среднее значение функции потерь на валидации 0.9594884141016815\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 64\n",
      "Эпоха: 89 итераций, 0.61 сек\n",
      "Среднее значение функции потерь на обучении 0.004966380519352937\n",
      "Среднее значение функции потерь на валидации 0.9647058824361381\n",
      "\n",
      "Эпоха 65\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004774780062372598\n",
      "Среднее значение функции потерь на валидации 0.9613664978641575\n",
      "\n",
      "Эпоха 66\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004949718624813838\n",
      "Среднее значение функции потерь на валидации 0.9606598100419772\n",
      "\n",
      "Эпоха 67\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004544892573331514\n",
      "Среднее значение функции потерь на валидации 0.9565802731756436\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 68\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004330353229306638\n",
      "Среднее значение функции потерь на валидации 0.960490658121594\n",
      "\n",
      "Эпоха 69\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004297289411338528\n",
      "Среднее значение функции потерь на валидации 0.96686563653461\n",
      "\n",
      "Эпоха 70\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.004139568685459789\n",
      "Среднее значение функции потерь на валидации 0.9612460479897967\n",
      "\n",
      "Эпоха 71\n",
      "Эпоха: 89 итераций, 0.67 сек\n",
      "Среднее значение функции потерь на обучении 0.003989162094880607\n",
      "Среднее значение функции потерь на валидации 0.9594865421117362\n",
      "\n",
      "Эпоха 72\n",
      "Эпоха: 89 итераций, 0.65 сек\n",
      "Среднее значение функции потерь на обучении 0.0038631717697978855\n",
      "Среднее значение функции потерь на валидации 0.9658395264108303\n",
      "\n",
      "Эпоха 73\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.003893403800759004\n",
      "Среднее значение функции потерь на валидации 0.9591527975211709\n",
      "Epoch    74: reducing learning rate of group 0 to 5.0000e-02.\n",
      "\n",
      "Эпоха 74\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.0035082568961268897\n",
      "Среднее значение функции потерь на валидации 0.9553486411854372\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 75\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.0033928780081378443\n",
      "Среднее значение функции потерь на валидации 0.952653706073761\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 76\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.0033496562430760666\n",
      "Среднее значение функции потерь на валидации 0.9536616670883308\n",
      "\n",
      "Эпоха 77\n",
      "Эпоха: 89 итераций, 1.13 сек\n",
      "Среднее значение функции потерь на обучении 0.003290863147821654\n",
      "Среднее значение функции потерь на валидации 0.9535996408785804\n",
      "\n",
      "Эпоха 78\n",
      "Эпоха: 89 итераций, 0.71 сек\n",
      "Среднее значение функции потерь на обучении 0.003246445411533703\n",
      "Среднее значение функции потерь на валидации 0.9534321972879313\n",
      "\n",
      "Эпоха 79\n",
      "Эпоха: 89 итераций, 0.62 сек\n",
      "Среднее значение функции потерь на обучении 0.0032605790595911194\n",
      "Среднее значение функции потерь на валидации 0.9524018926135565\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 80\n",
      "Эпоха: 89 итераций, 0.61 сек\n",
      "Среднее значение функции потерь на обучении 0.003253106791735365\n",
      "Среднее значение функции потерь на валидации 0.9518788022510076\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 81\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.0030548368564942913\n",
      "Среднее значение функции потерь на валидации 0.9549430295572443\n",
      "\n",
      "Эпоха 82\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.0030531119372109684\n",
      "Среднее значение функции потерь на валидации 0.9532860345759634\n",
      "\n",
      "Эпоха 83\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.0030584937220523027\n",
      "Среднее значение функции потерь на валидации 0.9537202857308469\n",
      "\n",
      "Эпоха 84\n",
      "Эпоха: 89 итераций, 0.62 сек\n",
      "Среднее значение функции потерь на обучении 0.002975528547017092\n",
      "Среднее значение функции потерь на валидации 0.9522527941202713\n",
      "\n",
      "Эпоха 85\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.002979076922651422\n",
      "Среднее значение функции потерь на валидации 0.951266063471972\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 86\n",
      "Эпоха: 89 итераций, 0.69 сек\n",
      "Среднее значение функции потерь на обучении 0.002871218864711818\n",
      "Среднее значение функции потерь на валидации 0.9508850109779229\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 87\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.0028437509873798224\n",
      "Среднее значение функции потерь на валидации 0.954454346228454\n",
      "\n",
      "Эпоха 88\n",
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.002799120595615901\n",
      "Среднее значение функции потерь на валидации 0.9524157633215694\n",
      "\n",
      "Эпоха 89\n",
      "Эпоха: 89 итераций, 0.64 сек\n",
      "Среднее значение функции потерь на обучении 0.0027708790665283128\n",
      "Среднее значение функции потерь на валидации 0.9514079942541608\n",
      "\n",
      "Эпоха 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха: 89 итераций, 0.66 сек\n",
      "Среднее значение функции потерь на обучении 0.0027152715954573805\n",
      "Среднее значение функции потерь на валидации 0.9526588260117224\n",
      "\n",
      "Эпоха 91\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.0026487120966102633\n",
      "Среднее значение функции потерь на валидации 0.9523390390105166\n",
      "\n",
      "Эпоха 92\n",
      "Эпоха: 89 итераций, 0.63 сек\n",
      "Среднее значение функции потерь на обучении 0.0026191354374757057\n",
      "Среднее значение функции потерь на валидации 0.9532406855437715\n",
      "Epoch    93: reducing learning rate of group 0 to 2.5000e-02.\n",
      "\n",
      "Эпоха 93\n",
      "Эпоха: 89 итераций, 0.70 сек\n",
      "Среднее значение функции потерь на обучении 0.0025011759010677257\n",
      "Среднее значение функции потерь на валидации 0.9510196901984134\n",
      "\n",
      "Эпоха 94\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.0024687186330870797\n",
      "Среднее значение функции потерь на валидации 0.9515345914889191\n",
      "\n",
      "Эпоха 95\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.002417329839415053\n",
      "Среднее значение функции потерь на валидации 0.9512493135565419\n",
      "\n",
      "Эпоха 96\n",
      "Эпоха: 89 итераций, 1.20 сек\n",
      "Среднее значение функции потерь на обучении 0.002407959706851103\n",
      "Среднее значение функции потерь на валидации 0.951561171119496\n",
      "\n",
      "Эпоха 97\n",
      "Эпоха: 89 итераций, 1.19 сек\n",
      "Среднее значение функции потерь на обучении 0.002420362527220604\n",
      "Среднее значение функции потерь на валидации 0.9511567010717877\n",
      "Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(UNIQUE_WORDS_N, UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, \n",
    "                                               patience=5, # кол-во эпох без улучшения\n",
    "                                               factor=0.5,\n",
    "                                               verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy, # категориальная кросс-энтропия с сигмойдой\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=100,\n",
    "                                            batch_size=128,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZHZIeZZ3VrT"
   },
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "gDQ5Q3kWEVlt"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def predict_with_model(model, \n",
    "                       dataset, \n",
    "                       device=None, \n",
    "                       batch_size=32, \n",
    "                       num_workers=0, \n",
    "                       return_labels=False):\n",
    "    \"\"\"\n",
    "    :param model: torch.nn.Module - обученная модель\n",
    "    :param dataset: torch.utils.data.Dataset - данные для применения модели\n",
    "    :param device: cuda/cpu - устройство, на котором выполнять вычисления\n",
    "    :param batch_size: количество примеров, обрабатываемых моделью за одну итерацию\n",
    "    :return: numpy.array размерности len(dataset) x *\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    device = torch.device(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    dataloader = DataLoader(dataset, \n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=False, \n",
    "                            num_workers=num_workers)\n",
    "    \n",
    "    results_by_batch = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in tqdm.tqdm(dataloader, \n",
    "                                          total=len(dataset)/batch_size):\n",
    "            batch_x = copy_data_to_device(batch_x, device)\n",
    "\n",
    "            if return_labels:\n",
    "                labels.append(batch_y.numpy())\n",
    "\n",
    "            batch_pred = model(batch_x)\n",
    "            results_by_batch.append(batch_pred.detach().cpu().numpy())\n",
    "\n",
    "    if return_labels:\n",
    "        return (np.concatenate(results_by_batch, axis=0), \n",
    "                np.concatenate(labels, axis=0))\n",
    "    else:\n",
    "        return np.concatenate(results_by_batch, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:25.105663Z",
     "start_time": "2019-09-12T12:46:22.373012Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OofbQyRl3VrT",
    "outputId": "01e21661-3ec0-4123-bf09-148aec906149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/353.5625 [00:01<00:00, 299.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 0.0026658219285309315\n",
      "Доля верных ответов 0.9995580696482235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:00, 289.42it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 0.9506846070289612\n",
      "Доля верных ответов 0.7631439192777483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55JzXQjJ3VrT"
   },
   "source": [
    "# Альтернативная реализация на scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:31.791405Z",
     "start_time": "2019-09-12T12:46:25.107897Z"
    },
    "id": "cwcVekYa3VrT",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "def tokenize_text_simple_regex(txt: str, \n",
    "                               token_pattern: re.Pattern = TOKEN_RE, \n",
    "                               min_token_size: int = 4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = token_pattern.findall(txt)\n",
    "    return list(filter(lambda x: len(x) >= min_token_size, all_tokens))\n",
    "\n",
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5\n",
    "\n",
    "sklearn_pipeline = Pipeline((\n",
    "    ('vect', TfidfVectorizer(tokenizer=tokenize_text_simple_regex, \n",
    "                             max_df=MAX_DF, \n",
    "                             min_df=MIN_COUNT)),\n",
    "    ('cls', LogisticRegression())\n",
    "    ))\n",
    "\n",
    "sklearn_pipeline.fit(train_source['data'], train_source['target']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGYvDRg63VrT"
   },
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-12T12:46:35.454567Z",
     "start_time": "2019-09-12T12:46:31.792832Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2gtnp6UF3VrT",
    "outputId": "b0e67a7b-2f4e-4482-a119-0d700e5cbafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 2.4954788918778026\n",
      "Доля верных ответов 0.9716280714159449\n",
      "\n",
      "Среднее значение функции потерь на валидации 2.6539022582507377\n",
      "Доля верных ответов 0.8190387679235263\n"
     ]
    }
   ],
   "source": [
    "sklearn_train_pred = sklearn_pipeline.predict_proba(train_source['data'])\n",
    "sklearn_train_loss = F.cross_entropy(torch.from_numpy(sklearn_train_pred),\n",
    "                                                 torch.from_numpy(train_source['target']))\n",
    "print('Среднее значение функции потерь на обучении', float(sklearn_train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], sklearn_train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "sklearn_test_pred = sklearn_pipeline.predict_proba(test_source['data'])\n",
    "sklearn_test_loss = F.cross_entropy(torch.from_numpy(sklearn_test_pred),\n",
    "                                                torch.from_numpy(test_source['target']))\n",
    "print('Среднее значение функции потерь на валидации', float(sklearn_test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], sklearn_test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшение модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление нормализации "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:task1_20newsgroups.ipynb
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 14,
   "metadata": {},
>>>>>>> c28fc094cc255f1432a8338419fcc843966fee13:1.task1_20newsgroups.ipynb
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[\\w\\d]+')\n",
    "\n",
    "def tokenize_text_simple_regex(txt: str, \n",
    "                               token_pattern: re.Pattern = TOKEN_RE, \n",
    "                               min_token_size: int = 4):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = token_pattern.findall(txt)\n",
    "    return list(filter(lambda x: len(x) >= min_token_size, all_tokens))\n",
    "\n",
    "def tokenize_text_with_normalization(txt: str, \n",
    "                                     normalization_type: str = \"lemmatize\"):\n",
    "    assert normalization_type in [\"stem\", \"lemmatize\"], \"Unknown normalization type\"\n",
    "    \n",
    "    if normalization_type == \"stem\":\n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        norm_func = ps.stem\n",
    "    elif normalization_type == \"lemmatize\":\n",
    "        lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "        norm_func = lemma.lemmatize\n",
    "    \n",
    "    tokens = tokenize_text_simple_regex(txt)\n",
    "    return [norm_func(token) for token in tokens]\n",
    "\n",
    "MAX_DF = 0.8\n",
    "MIN_COUNT = 5\n",
    "\n",
    "vect = TfidfVectorizer(tokenizer=tokenize_text_with_normalization, \n",
    "                       max_df=MAX_DF, \n",
    "                       min_df=MIN_COUNT)\n",
    "\n",
    "train_vectors = vect.fit_transform(train_source[\"data\"])\n",
    "test_vectors = vect.transform(test_source[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Эпоха 0\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.7797437479321876\n",
      "Среднее значение функции потерь на валидации 0.6400418321965105\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.04919201355385647\n",
      "Среднее значение функции потерь на валидации 0.61752456982257\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.020789481040215895\n",
      "Среднее значение функции потерь на валидации 0.6167564089015379\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.013166847309160434\n",
      "Среднее значение функции потерь на валидации 0.613809926024938\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.01010219809818971\n",
      "Среднее значение функции потерь на валидации 0.6149499598195998\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.009718567378860846\n",
      "Среднее значение функции потерь на валидации 0.6199631357597093\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 89 итераций, 0.74 сек\n",
      "Среднее значение функции потерь на обучении 0.007292741525060173\n",
      "Среднее значение функции потерь на валидации 0.6216001263109304\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 89 итераций, 1.42 сек\n",
      "Среднее значение функции потерь на обучении 0.006899476571929421\n",
      "Среднее значение функции потерь на валидации 0.6211720482777741\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 89 итераций, 1.50 сек\n",
      "Среднее значение функции потерь на обучении 0.00614807128205142\n",
      "Среднее значение функции потерь на валидации 0.6261208900960825\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 89 итераций, 1.52 сек\n",
      "Среднее значение функции потерь на обучении 0.004781822585029884\n",
      "Среднее значение функции потерь на валидации 0.6257519954341954\n",
      "Epoch    10: reducing learning rate of group 0 to 1.0000e-02.\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 89 итераций, 1.52 сек\n",
      "Среднее значение функции потерь на обучении 0.003919504101524193\n",
      "Среднее значение функции потерь на валидации 0.6257204479080135\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 89 итераций, 1.62 сек\n",
      "Среднее значение функции потерь на обучении 0.0034459426768877533\n",
      "Среднее значение функции потерь на валидации 0.6258587175506657\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 89 итераций, 0.99 сек\n",
      "Среднее значение функции потерь на обучении 0.003220477127051504\n",
      "Среднее значение функции потерь на валидации 0.6262562234522933\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 89 итераций, 0.77 сек\n",
      "Среднее значение функции потерь на обучении 0.003073795996815636\n",
      "Среднее значение функции потерь на валидации 0.6264879491369603\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 89 итераций, 0.73 сек\n",
      "Среднее значение функции потерь на обучении 0.0030025494235222426\n",
      "Среднее значение функции потерь на валидации 0.6268064637305373\n",
      "Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])\n",
    "\n",
    "model = nn.Linear(train_vectors.shape[1], UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, \n",
    "                                               patience=5, # кол-во эпох без улучшения\n",
    "                                               factor=0.1,\n",
    "                                               verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy, # категориальная кросс-энтропия с сигмойдой\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=100,\n",
    "                                            batch_size=128,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/353.5625 [00:00<00:00, 515.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 0.009176941588521004\n",
      "Доля верных ответов 0.9991161392964468\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:00, 510.46it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 0.6137064099311829\n",
      "Доля верных ответов 0.823287307488051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-граммы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text: str, \n",
    "                  norm_type: str = None,\n",
    "                  ngrams: int = 1,\n",
    "                  min_word_len: int = None):\n",
    "    assert norm_type in [\"stem\", \"lemmatize\", None], \"Unknown normalization type\"\n",
    "\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "    if min_word_len is not None:\n",
    "        tokens = filter(lambda token: len(token) >= min_word_len, tokens)\n",
    "    \n",
    "    if norm_type is not None:\n",
    "        if norm_type == \"stem\":\n",
    "            ps = nltk.stem.PorterStemmer()\n",
    "            norm_func = ps.stem\n",
    "        elif norm_type == \"lemmatize\":\n",
    "            lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "            norm_func = lemma.lemmatize\n",
    "        tokens = [norm_func(token) for token in tokens]\n",
    "    \n",
    "    tokens = [\" \".join(token) for token in nltk.ngrams(tokens, n=ngrams)]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=lambda x: tokenize_text(x, \n",
    "                                                         norm_type=\"stem\",\n",
    "                                                         ngrams=2,\n",
    "                                                         min_word_len=4), \n",
    "                       max_df=MAX_DF, \n",
    "                       min_df=MIN_COUNT)\n",
    "\n",
    "train_vectors = vect.fit_transform(train_source[\"data\"])\n",
    "test_vectors = vect.transform(test_source[\"data\"])\n",
    "\n",
    "UNIQUE_WORDS_N = train_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(UNIQUE_WORDS_N, 128),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(64, UNIQUE_LABELS_N)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Эпоха 0\n",
      "Эпоха: 89 итераций, 1.47 сек\n",
      "Среднее значение функции потерь на обучении 3.0528953155774747\n",
      "Среднее значение функции потерь на валидации 3.0123638258141985\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 1\n",
      "Эпоха: 89 итераций, 1.46 сек\n",
      "Среднее значение функции потерь на обучении 3.0305848335951904\n",
      "Среднее значение функции потерь на валидации 3.0255433502843823\n",
      "\n",
      "Эпоха 2\n",
      "Эпоха: 89 итераций, 1.51 сек\n",
      "Среднее значение функции потерь на обучении 3.031820766041788\n",
      "Среднее значение функции потерь на валидации 3.014666128966768\n",
      "\n",
      "Эпоха 3\n",
      "Эпоха: 89 итераций, 1.47 сек\n",
      "Среднее значение функции потерь на обучении 3.033045779453235\n",
      "Среднее значение функции потерь на валидации 3.025055998462742\n",
      "\n",
      "Эпоха 4\n",
      "Эпоха: 89 итераций, 1.51 сек\n",
      "Среднее значение функции потерь на обучении 3.0275866610280584\n",
      "Среднее значение функции потерь на валидации 3.0131690017247603\n",
      "\n",
      "Эпоха 5\n",
      "Эпоха: 89 итераций, 2.13 сек\n",
      "Среднее значение функции потерь на обучении 3.026868187979366\n",
      "Среднее значение функции потерь на валидации 3.011786452794479\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 6\n",
      "Эпоха: 89 итераций, 1.93 сек\n",
      "Среднее значение функции потерь на обучении 3.0352428789888877\n",
      "Среднее значение функции потерь на валидации 3.0100478317777988\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 7\n",
      "Эпоха: 89 итераций, 2.17 сек\n",
      "Среднее значение функции потерь на обучении 3.02897755483563\n",
      "Среднее значение функции потерь на валидации 3.016740746417288\n",
      "\n",
      "Эпоха 8\n",
      "Эпоха: 89 итераций, 2.03 сек\n",
      "Среднее значение функции потерь на обучении 3.029555722568812\n",
      "Среднее значение функции потерь на валидации 3.0271237543073752\n",
      "\n",
      "Эпоха 9\n",
      "Эпоха: 89 итераций, 1.62 сек\n",
      "Среднее значение функции потерь на обучении 3.0253797273957326\n",
      "Среднее значение функции потерь на валидации 3.019523673138376\n",
      "\n",
      "Эпоха 10\n",
      "Эпоха: 89 итераций, 2.33 сек\n",
      "Среднее значение функции потерь на обучении 3.033320429619778\n",
      "Среднее значение функции потерь на валидации 3.0194211571903553\n",
      "\n",
      "Эпоха 11\n",
      "Эпоха: 89 итераций, 2.11 сек\n",
      "Среднее значение функции потерь на обучении 3.0297330149104087\n",
      "Среднее значение функции потерь на валидации 3.012301731917818\n",
      "\n",
      "Эпоха 12\n",
      "Эпоха: 89 итераций, 2.24 сек\n",
      "Среднее значение функции потерь на обучении 3.031993697198589\n",
      "Среднее значение функции потерь на валидации 3.0196790250681214\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-02.\n",
      "\n",
      "Эпоха 13\n",
      "Эпоха: 89 итераций, 1.51 сек\n",
      "Среднее значение функции потерь на обучении 3.001834097872959\n",
      "Среднее значение функции потерь на валидации 2.9917862940642794\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 14\n",
      "Эпоха: 89 итераций, 1.55 сек\n",
      "Среднее значение функции потерь на обучении 2.9947443088788663\n",
      "Среднее значение функции потерь на валидации 2.9932380288334217\n",
      "\n",
      "Эпоха 15\n",
      "Эпоха: 89 итераций, 1.59 сек\n",
      "Среднее значение функции потерь на обучении 2.9943846102510947\n",
      "Среднее значение функции потерь на валидации 2.9921770499924483\n",
      "\n",
      "Эпоха 16\n",
      "Эпоха: 89 итераций, 2.30 сек\n",
      "Среднее значение функции потерь на обучении 2.9954210372453325\n",
      "Среднее значение функции потерь на валидации 2.9924494896904896\n",
      "\n",
      "Эпоха 17\n",
      "Эпоха: 89 итераций, 2.03 сек\n",
      "Среднее значение функции потерь на обучении 2.9947573334983226\n",
      "Среднее значение функции потерь на валидации 2.9916424508822166\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 18\n",
      "Эпоха: 89 итераций, 2.08 сек\n",
      "Среднее значение функции потерь на обучении 2.994011169069269\n",
      "Среднее значение функции потерь на валидации 2.992365053144552\n",
      "\n",
      "Эпоха 19\n",
      "Эпоха: 89 итераций, 1.80 сек\n",
      "Среднее значение функции потерь на обучении 2.9953125648284225\n",
      "Среднее значение функции потерь на валидации 2.9928398334373862\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "Эпоха 20\n",
      "Эпоха: 89 итераций, 1.48 сек\n",
      "Среднее значение функции потерь на обучении 2.9933603292100885\n",
      "Среднее значение функции потерь на валидации 2.9907829519045555\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 21\n",
      "Эпоха: 89 итераций, 1.57 сек\n",
      "Среднее значение функции потерь на обучении 2.9915451842747376\n",
      "Среднее значение функции потерь на валидации 2.9903922565912797\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 22\n",
      "Эпоха: 89 итераций, 1.67 сек\n",
      "Среднее значение функции потерь на обучении 2.99097088213717\n",
      "Среднее значение функции потерь на валидации 2.9903129925162104\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 23\n",
      "Эпоха: 89 итераций, 2.34 сек\n",
      "Среднее значение функции потерь на обучении 2.9913108322057833\n",
      "Среднее значение функции потерь на валидации 2.9903077998403775\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 24\n",
      "Эпоха: 89 итераций, 2.31 сек\n",
      "Среднее значение функции потерь на обучении 2.991647586393892\n",
      "Среднее значение функции потерь на валидации 2.9903079736030707\n",
      "\n",
      "Эпоха 25\n",
      "Эпоха: 89 итераций, 2.11 сек\n",
      "Среднее значение функции потерь на обучении 2.9914495864610995\n",
      "Среднее значение функции потерь на валидации 2.990302223270222\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 26\n",
      "Эпоха: 89 итераций, 1.54 сек\n",
      "Среднее значение функции потерь на обучении 2.9910594988405035\n",
      "Среднее значение функции потерь на валидации 2.990295260639514\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 27\n",
      "Эпоха: 89 итераций, 1.94 сек\n",
      "Среднее значение функции потерь на обучении 2.9914910578995606\n",
      "Среднее значение функции потерь на валидации 2.9903291928566107\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "Эпоха 28\n",
      "Эпоха: 89 итераций, 1.85 сек\n",
      "Среднее значение функции потерь на обучении 2.991099847836441\n",
      "Среднее значение функции потерь на валидации 2.990316483934047\n",
      "\n",
      "Эпоха 29\n",
      "Эпоха: 89 итераций, 1.53 сек\n",
      "Среднее значение функции потерь на обучении 2.990149736404419\n",
      "Среднее значение функции потерь на валидации 2.990315792924267\n",
      "\n",
      "Эпоха 30\n",
      "Эпоха: 89 итераций, 1.90 сек\n",
      "Среднее значение функции потерь на обучении 2.990604384561603\n",
      "Среднее значение функции потерь на валидации 2.9903057470160017\n",
      "\n",
      "Эпоха 31\n",
      "Эпоха: 89 итераций, 1.71 сек\n",
      "Среднее значение функции потерь на обучении 2.9908151251546453\n",
      "Среднее значение функции потерь на валидации 2.990302178819301\n",
      "\n",
      "Эпоха 32\n",
      "Эпоха: 89 итераций, 2.11 сек\n",
      "Среднее значение функции потерь на обучении 2.9906074116738997\n",
      "Среднее значение функции потерь на валидации 2.9902959799362443\n",
      "\n",
      "Эпоха 33\n",
      "Эпоха: 89 итераций, 1.94 сек\n",
      "Среднее значение функции потерь на обучении 2.990377144867115\n",
      "Среднее значение функции потерь на валидации 2.9902900800866594\n",
      "Новая лучшая модель!\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "Эпоха 34\n",
      "Эпоха: 89 итераций, 1.78 сек\n",
      "Среднее значение функции потерь на обучении 2.9903867351874878\n",
      "Среднее значение функции потерь на валидации 2.990289768930209\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 35\n",
      "Эпоха: 89 итераций, 1.56 сек\n",
      "Среднее значение функции потерь на обучении 2.9907683951131414\n",
      "Среднее значение функции потерь на валидации 2.990289490101701\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 36\n",
      "Эпоха: 89 итераций, 1.58 сек\n",
      "Среднее значение функции потерь на обучении 2.9903425098804943\n",
      "Среднее значение функции потерь на валидации 2.9902887506000067\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 37\n",
      "Эпоха: 89 итераций, 1.98 сек\n",
      "Среднее значение функции потерь на обучении 2.9904749393463135\n",
      "Среднее значение функции потерь на валидации 2.9902883384187344\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 38\n",
      "Эпоха: 89 итераций, 1.59 сек\n",
      "Среднее значение функции потерь на обучении 2.99086795764023\n",
      "Среднее значение функции потерь на валидации 2.9902886051242636\n",
      "\n",
      "Эпоха 39\n",
      "Эпоха: 89 итераций, 2.36 сек\n",
      "Среднее значение функции потерь на обучении 2.9907507869634737\n",
      "Среднее значение функции потерь на валидации 2.9902883020497986\n",
      "Новая лучшая модель!\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-06.\n",
      "\n",
      "Эпоха 40\n",
      "Эпоха: 89 итераций, 2.03 сек\n",
      "Среднее значение функции потерь на обучении 2.990725297606393\n",
      "Среднее значение функции потерь на валидации 2.9902881808200124\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 41\n",
      "Эпоха: 89 итераций, 1.84 сек\n",
      "Среднее значение функции потерь на обучении 2.9902124378118624\n",
      "Среднее значение функции потерь на валидации 2.990288192942991\n",
      "\n",
      "Эпоха 42\n",
      "Эпоха: 89 итераций, 1.69 сек\n",
      "Среднее значение функции потерь на обучении 2.9907726411069375\n",
      "Среднее значение функции потерь на валидации 2.9902881767790195\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 43\n",
      "Эпоха: 89 итераций, 1.51 сек\n",
      "Среднее значение функции потерь на обучении 2.9911200785904786\n",
      "Среднее значение функции потерь на валидации 2.9902881848610052\n",
      "\n",
      "Эпоха 44\n",
      "Эпоха: 89 итераций, 1.50 сек\n",
      "Среднее значение функции потерь на обучении 2.9908404055606113\n",
      "Среднее значение функции потерь на валидации 2.9902880636312195\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 45\n",
      "Эпоха: 89 итераций, 1.64 сек\n",
      "Среднее значение функции потерь на обучении 2.9906704291868746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 2.990288019180298\n",
      "Новая лучшая модель!\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-07.\n",
      "\n",
      "Эпоха 46\n",
      "Эпоха: 89 итераций, 2.26 сек\n",
      "Среднее значение функции потерь на обучении 2.9907518960116954\n",
      "Среднее значение функции потерь на валидации 2.990288192942991\n",
      "\n",
      "Эпоха 47\n",
      "Эпоха: 89 итераций, 2.22 сек\n",
      "Среднее значение функции потерь на обучении 2.99064948853482\n",
      "Среднее значение функции потерь на валидации 2.990287897950512\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 48\n",
      "Эпоха: 89 итераций, 1.69 сек\n",
      "Среднее значение функции потерь на обучении 2.9907818456714073\n",
      "Среднее значение функции потерь на валидации 2.990288104041148\n",
      "\n",
      "Эпоха 49\n",
      "Эпоха: 89 итераций, 1.64 сек\n",
      "Среднее значение функции потерь на обучении 2.9908015969094266\n",
      "Среднее значение функции потерь на валидации 2.9902879908933477\n",
      "\n",
      "Эпоха 50\n",
      "Эпоха: 89 итераций, 2.12 сек\n",
      "Среднее значение функции потерь на обучении 2.9908021675067\n",
      "Среднее значение функции потерь на валидации 2.9902879666473905\n",
      "\n",
      "Эпоха 51\n",
      "Эпоха: 89 итераций, 2.24 сек\n",
      "Среднее значение функции потерь на обучении 2.9909704990601274\n",
      "Среднее значение функции потерь на валидации 2.9902879706883834\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-08.\n",
      "\n",
      "Эпоха 52\n",
      "Эпоха: 89 итераций, 1.50 сек\n",
      "Среднее значение функции потерь на обучении 2.990630133768146\n",
      "Среднее значение функции потерь на валидации 2.9902878575405833\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 53\n",
      "Эпоха: 89 итераций, 1.52 сек\n",
      "Среднее значение функции потерь на обучении 2.990690571538518\n",
      "Среднее значение функции потерь на валидации 2.9902879424014333\n",
      "\n",
      "Эпоха 54\n",
      "Эпоха: 89 итераций, 2.01 сек\n",
      "Среднее значение функции потерь на обучении 2.990499089273174\n",
      "Среднее значение функции потерь на валидации 2.9902878494585976\n",
      "Новая лучшая модель!\n",
      "\n",
      "Эпоха 55\n",
      "Эпоха: 89 итераций, 2.40 сек\n",
      "Среднее значение функции потерь на обучении 2.990567850262931\n",
      "Среднее значение функции потерь на валидации 2.9902879302784546\n",
      "\n",
      "Эпоха 56\n",
      "Эпоха: 89 итераций, 2.38 сек\n",
      "Среднее значение функции потерь на обучении 2.9909148376979187\n",
      "Среднее значение функции потерь на валидации 2.990288083836184\n",
      "\n",
      "Эпоха 57\n",
      "Эпоха: 89 итераций, 2.12 сек\n",
      "Среднее значение функции потерь на обучении 2.990795807892017\n",
      "Среднее значение функции потерь на валидации 2.990288015139305\n",
      "\n",
      "Эпоха 58\n",
      "Эпоха: 89 итераций, 2.05 сек\n",
      "Среднее значение функции потерь на обучении 2.99062101224835\n",
      "Среднее значение функции потерь на валидации 2.9902879424014333\n",
      "\n",
      "Эпоха 59\n",
      "Эпоха: 89 итераций, 1.49 сек\n",
      "Среднее значение функции потерь на обучении 2.9905825143449762\n",
      "Среднее значение функции потерь на валидации 2.9902879262374618\n",
      "\n",
      "Эпоха 60\n",
      "Эпоха: 89 итераций, 1.45 сек\n",
      "Среднее значение функции потерь на обучении 2.990447443522764\n",
      "Среднее значение функции потерь на валидации 2.9902880232212907\n",
      "\n",
      "Эпоха 61\n",
      "Эпоха: 89 итераций, 1.43 сек\n",
      "Среднее значение функции потерь на обучении 2.9906453684474643\n",
      "Среднее значение функции потерь на валидации 2.9902879343194475\n",
      "\n",
      "Эпоха 62\n",
      "Эпоха: 89 итераций, 1.43 сек\n",
      "Среднее значение функции потерь на обучении 2.9912469922826532\n",
      "Среднее значение функции потерь на валидации 2.990287865622569\n",
      "\n",
      "Эпоха 63\n",
      "Эпоха: 89 итераций, 1.43 сек\n",
      "Среднее значение функции потерь на обучении 2.9907408001717557\n",
      "Среднее значение функции потерь на валидации 2.9902879100734903\n",
      "\n",
      "Эпоха 64\n",
      "Эпоха: 89 итераций, 1.43 сек\n",
      "Среднее значение функции потерь на обучении 2.990773576029231\n",
      "Среднее значение функции потерь на валидации 2.9902880595902266\n",
      "\n",
      "Эпоха 65\n",
      "Эпоха: 89 итераций, 1.43 сек\n",
      "Среднее значение функции потерь на обучении 2.99117990290181\n",
      "Среднее значение функции потерь на валидации 2.9902880636312195\n",
      "Модель не улучшилась за последние 10 эпох, прекращаем обучение\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SparseFeaturesDataset(train_vectors, train_source['target'])\n",
    "test_dataset = SparseFeaturesDataset(test_vectors, test_source['target'])\n",
    "\n",
    "# model = nn.Linear(train_vectors.shape[1], UNIQUE_LABELS_N)\n",
    "\n",
    "scheduler = lambda optim: \\\n",
    "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, \n",
    "                                               patience=5, # кол-во эпох без улучшения\n",
    "                                               factor=0.1,\n",
    "                                               verbose=True)\n",
    "\n",
    "best_val_loss, best_model = train_eval_loop(model=model,\n",
    "                                            train_dataset=train_dataset,\n",
    "                                            val_dataset=test_dataset,\n",
    "                                            criterion=F.cross_entropy, # категориальная кросс-энтропия с сигмойдой\n",
    "                                            lr=1e-1,\n",
    "                                            epoch_n=100,\n",
    "                                            batch_size=128,\n",
    "                                            l2_reg_alpha=0,\n",
    "                                            lr_scheduler_ctor=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354/353.5625 [00:01<00:00, 336.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на обучении 2.9902806282043457\n",
      "Доля верных ответов 0.052943256142831886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [00:00, 337.57it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение функции потерь на валидации 2.9902961254119873\n",
      "Доля верных ответов 0.05284121083377589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred = predict_with_model(best_model, train_dataset)\n",
    "\n",
    "train_loss = F.cross_entropy(torch.from_numpy(train_pred),\n",
    "                             torch.from_numpy(train_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на обучении', float(train_loss))\n",
    "print('Доля верных ответов', accuracy_score(train_source['target'], train_pred.argmax(-1)))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "test_pred = predict_with_model(best_model, test_dataset)\n",
    "\n",
    "test_loss = F.cross_entropy(torch.from_numpy(test_pred),\n",
    "                            torch.from_numpy(test_source['target']).long())\n",
    "\n",
    "print('Среднее значение функции потерь на валидации', float(test_loss))\n",
    "print('Доля верных ответов', accuracy_score(test_source['target'], test_pred.argmax(-1)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "stepic_nlp_task1_20newsgroups.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
